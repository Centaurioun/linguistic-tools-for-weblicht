<!DOCTYPE html>
<html>
    <head>
        <title>ILC4CLARIN Tokenizer services</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>
    <body>
        <h2>ILC4CLARIN Offered Services</h2>
        <p>ILC4CLARIN provides three sets of distinct web services to perform tokenization on texts for the following languages: 
        <ul>
            <li>ita</li> 
            <li>fra</li>
            <li>deu</li>
            <li>eng</li>
            <li>esp</li>
            <li>nld</li>
        </ul>
        The application arises an <b>Unsupported Language Exception</b> if the language provided is not in the list.

        <p>Offered services perform the same operation (tokenization), but, according with the endpoints, valid <a href="https://weblicht.sfs.uni-tuebingen.de/weblichtwiki/index.php/The_TCF_Format" target="_blank">
                TCF</a>, 
            <a href="https://github.com/opener-project/kaf/wiki/KAF-structure-overview" target="_blank">KAF</a> or tabbed files 
            can be produced.
            <br></br>
            The service that produces TCF can read from both a plain text or a valid TCF document. The mimetype is set accordingly. 
        </p>
        <p></p>
        <p></p>
        <p></p>
        <p>This page explains how to invoke the offered services.</p>
        <p>The endpoints are the following:</p>
        <ul>
            <li><code>wl/tokenizer/plain</code> (POST service to tokenize plain text and to produce a TCF valid document)</li>
            <li><code>wl/tokenizer/lrs</code> (GET service to tokenize a text retrieved from URL  and to produce a TCF valid document)</li>
            <li><code>wl/tokenizer/tcf</code> (POST service to tokenize TCF document and to produce a TCF valid document)</li>
            <li></li>
            <li><code>kaf/tokenizer/plain</code> (POST service to tokenize plain texts and to produce a KAF valid document)</li>
            <li><code>kaf/tokenizer/lrs</code> (GET service to tokenize a text retrieved from URL  and to produce a KAF valid document)</li>
            <li></li>
            <li><code>tab/tokenizer/plain</code> (POST service to tokenize plain texts and to produce a tabbed document)</li>
            <li><code>tab/tokenizer/lrs</code> (GET service to tokenize a text retrieved from URL  and to produce a tabbed document)</li>
        </ul>
        <p>The language is provided as a parameter: </p>
        <ul>
            <li><code>wl/tokenizer/plain?lang=iso_3_codes_lang</code></li>
            <li><code>wl/tokenizer/tcf?lang=iso_3_codes_lang</code></li>
            <li></li>
            <li><code>kaf/tokenizer/plain?lang=iso_3_codes_lang</code></li>
            <li></li>
            <li><code>tab/tokenizer/plain?lang=iso_3_codes_lang</code></li>
        </ul>

        <p></p>
        <p>For Language Resource Switchboard (please note the lrs in the path) we added three additional endpoints</p>
        <p>The endpoints are the following:</p>
        <ul>
            <li><code>wl/tokenizer/lrs</code> (GET service to tokenize a text retrieved from URL  and to produce a TCF valid document)</li>
            <li></li>
            <li><code>kaf/tokenizer/lrs</code> (GET service to tokenize a text retrieved from URL  and to produce a KAF valid document)</li>
            <li></li>
            <li><code>tab/tokenizer/lrs</code> (GET service to tokenize a text retrieved from URL  and to produce a tabbed document)</li>
        </ul>
        <p>Both the language and the url are provided as a parameters: </p>
        <ul>
            <li><code>wl/tokenizer/lrs?lang=iso_3_codes_lang&amp;url=URL</code></li>
            <li></li>
            <li><code>kaf/tokenizer/lrs?lang=iso_3_codes_lang&amp;url=URL</code></li>
            <li></li>
            <li><code>/tab/tokenizer/lrs?lang=iso_3_codes_lang&amp;url=URL</code></li>
        </ul>
        This because the integration of services in Language Resource Switchboard requires the URL passed as an input parameter.
        <p>You can test the service endpoints using curl or wget as follows:</p>
        <ul>

            <li>Send the input file to the endpoints for processing:
                <br></br>
                With curl:
                <br></br>
                <code> curl -H 'content-type: text/plain' --data-binary @plain-file.txt -X POST <span class="url"></span>wl/tokenizer/plain?lang=ita</code>
                <br></br>
                <code> curl -H 'content-type: text/tcf+xml' --data-binary @tcf-file.txt -X POST <span class="url"></span>wl/tokenizer/tcf?lang=ita</code>
                <br></br>
                <code> curl -H 'content-type: text/plain' --data-binary @plain-file.txt -X POST <span class="url"></span>kaf/tokenizer/plain?lang=ita</code>
                <br></br>
                <code> curl -H 'content-type: text/plain' --data-binary @plain-file.txt -X POST <span class="url"></span>tab/tokenizer/plain?lang=it</code>

                <br></br>
                Or wget:
                <br></br>
                <code> wget --post-file=plain-file.txt --header='Content-Type: text/plain' <span class="url"></span>wl/tokenizer/plain?lang=ita</code>
                <br></br>
                <code> wget --post-file=tcf-file.txt --header='Content-Type: text/tcf+xml' <span class="url"></span>wl/tokenizer/tcf?lang=ita</code>
                <br></br>
                <code> wget --post-file=plain-file.txt --header='Content-Type: text/plain' <span class="url"></span>kaf/tokenizer/plain?lang=ita</code>
                <br></br>
                <code> wget --post-file=plain-file.txt --header='Content-Type: text/plain' <span class="url"></span>tab/tokenizer/plain?lang=ita</code>
                <br></br>

            </li>

            <li>To test the services for language Resource Switchboard:
                <br></br>With curl:

                <code> curl -X GET  &quot;http://localhost:8100/services/wl/tokenizer/lrs?lang=ita&url=https://raw.githubusercontent.com/clarin-eric/LRS-Hackathon/master/samples/resources/txt/hermes-it.txt&quot;
                </code>
                <br></br>
                <code> curl -X GET  &quot;http://localhost:8100/services/kaf/tokenizer/lrs?lang=ita&url=https://raw.githubusercontent.com/clarin-eric/LRS-Hackathon/master/samples/resources/txt/hermes-it.txt&quot;
                </code>
                <br></br>
                <code> curl -X GET  &quot;http://localhost:8100/services/tab/tokenizer/lrs?lang=ita&url=https://raw.githubusercontent.com/clarin-eric/LRS-Hackathon/master/samples/resources/txt/hermes-it.txt&quot;
                </code>

                <br></br>
                Or wget:
                <br></br>
                <code>  wget  &quot;http://localhost:8100/services/wl/tokenizer/lrs?lang=ita&url=https://raw.githubusercontent.com/clarin-eric/LRS-Hackathon/master/samples/resources/txt/hermes-it.txt&quot; [-O out_file]</code>

                <br></br>
                <code>  wget  &quot;http://localhost:8100/services/kaf/tokenizer/lrs?lang=ita&url=https://raw.githubusercontent.com/clarin-eric/LRS-Hackathon/master/samples/resources/txt/hermes-it.txt&quot; [-O out_file]</code>

                <br></br>
                <code>  wget  &quot;http://localhost:8100/services/tab/tokenizer/lrs?lang=ita&url=https://raw.githubusercontent.com/clarin-eric/LRS-Hackathon/master/samples/resources/txt/hermes-it.txt&quot; [-O out_file]</code>
                <br></br>

            </li>
        </ul>
        <p><b>Please note that </b> services designed for Language Resource Switchboard clearly work by themselves invoking the commands above.</p>


        As for plain text you can use <pre> Mi chiamo Riccardo. Abito a Roma</pre>

        As for TCF text you can use <pre>
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-model href=&quot;http://de.clarin.eu/images/weblicht-tutorials/resources/tcf-04/schemas/latest/d-spin_0_4.rnc&quot; type=&quot;application/relax-ng-compact-syntax&quot;?&gt;
    &lt;D-Spin xmlns=&quot;http://www.dspin.de/data&quot; version=&quot;0.4&quot;&gt;
        &lt;md:MetaData xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:cmd=&quot;http://www.clarin.eu/cmd/&quot; 
            xmlns:md=&quot;http://www.dspin.de/data/metadata&quot; 
            xsi:schemaLocation=&quot;http://www.clarin.eu/cmd/ http://catalog.clarin.eu/ds/ComponentRegistry/rest/registry/profiles/clarin.eu:cr1:p_1320657629623/xsd&quot;&gt;
        &lt;/md:MetaData&gt;
            &lt;tc:TextCorpus xmlns:tc=&quot;http://www.dspin.de/data/textcorpus&quot; lang=&quot;it&quot;&gt;
                &lt;tc:text&gt;
                    Mi chiamo Alfredo. Abito a Roma.
                &lt;/tc:text&gt;
            &lt;/tc:TextCorpus&gt;
    &lt;/D-Spin&gt;
        </pre>

        <h2>Contacts</h2>
        In case of problems write an email to <a href="mailto:ILC-Clarin-tech-staff@ilc.cnr.it?subject=Problems in ILC4CLARIN Offered services">The ILC4CLARIN technical staff</a> with all the information needed to solve the issues.

        <script type="text/javascript">
            var elemList = document.getElementsByClassName("url");
            for (var i = 0; i < elemList.length; i++) {
                elemList[i].innerHTML = window.location.href;
            }
        </script>
    </body>
</html>
